#!/usr/bin/python2

## SecuML
## Copyright (C) 2016  ANSSI
##
## SecuML is free software; you can redistribute it and/or modify
## it under the terms of the GNU General Public License as published by
## the Free Software Foundation; either version 2 of the License, or
## (at your option) any later version.
##
## SecuML is distributed in the hope that it will be useful,
## but WITHOUT ANY WARRANTY; without even the implied warranty of
## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
## GNU General Public License for more details.
##
## You should have received a copy of the GNU General Public License along
## with SecuML. If not, see <http://www.gnu.org/licenses/>.

import argparse
import numpy as np
import matplotlib
matplotlib.use('Agg')

from SecuML.Data.Dataset import Dataset
from SecuML.Experiment.SupervisedLearningExperiment \
        import SupervisedLearningExperiment

from SecuML.UnsupervisedLearning.Configuration import ProjectionConfFactory
from SecuML.UnsupervisedLearning.Configuration import ClusteringConfFactory

from SecuML.SupervisedLearning.Configuration.AlertsConfiguration \
        import AlertsConfiguration
from SecuML.SupervisedLearning.Configuration import SupervisedLearningConfFactory
from SecuML.SupervisedLearning.SupervisedLearningDatasets \
        import SupervisedLearningDatasets
from SecuML.Tools import mysql_tools


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
            description = 'Learn a supervised detection model. ' + 
            'The labels must be stored in labels/true_labels.csv.')
    parser.add_argument('project')
    parser.add_argument('dataset')
    parser.add_argument('--features', '-f',
            dest = 'features_files',
            nargs = '+',
            required = False,
            default = ['features.csv'],
            help = 'CSV files containing the features.')
    
    ## Cross validation parameters
    cv_group = parser.add_argument_group(
            'Cross validation parameters')
    cv_group.add_argument('--num-folds',
            type = int,
            default = 4)
    cv_group.add_argument('--model-class',
            choices = ['LogisticRegression', 'Svc'],
            default = 'LogisticRegression')
    sample_weight_help  = 'When set to True, the detection model is learned with '
    sample_weight_help += 'sample weights inverse to the proportion of the family '
    sample_weight_help += 'in the dataset. Useless if the sublabels are not specified.'
    cv_group.add_argument('--sample-weight',
            action = 'store_true',
            default = False,
            help = sample_weight_help)
    
    ## Validation parameters
    validation_help  = 'Validation parameters: \n '
    validation_help += 'The detection model is validated with a proportion of '
    validation_help += 'the instances in the input dataset, or with a separate validation'
    validation_help += ' dataset. By default 10% of the instances are used for validation'
    validation_group = parser.add_argument_group(validation_help)
    validation_group.add_argument('--test-size',
            type = float,
            default = 0.1)
    validation_group.add_argument('--validation-dataset',
            default = None)
    
    ## Alerts
    alerts_group = parser.add_argument_group(
            'Alerts parameters')
    alerts_group.add_argument('--top-n-alerts',
            default = 100,
            help = 'Number of most confident alerts displayed.')
    alerts_group.add_argument('--detection-threshold',
            type = float,
            default = 0.8,
            help = 'An alert is raised if the predicted probability of maliciousness ' +
            'is above this threshold.')
    alerts_group.add_argument('--clustering-algo',
            default = 'Kmeans',
            choices = ['Kmeans', 'GaussianMixture'],
            help = 'Clustering algorithm to analyse the alerts.')
    num_clusters_help  = 'Number of clusters built from the alerts if the sublabels are '
    num_clusters_help += 'not specified in the training dataset. '
    num_clusters_help += 'Otherwise, the number of clusters is set to the number of '
    num_clusters_help += 'malicious families in the training dataset.'
    alerts_group.add_argument('--num-clusters',
            type = int,
            default = 4,
            help = num_clusters_help)
    soft_constraints_help  = 'Semi supervised clustering based on the sublabels of the '
    soft_constraints_help += 'training instances. It enables to get clusters regrouping '
    soft_constraints_help += 'user defined malicious families. Useless if the sublabels '
    soft_constraints_help += 'are not specified. '
    soft_constraints_help += 'The clustering is built without any constraint by default.'
    alerts_group.add_argument('--soft-constraints',
            choices = ['Lda', 'Sdml', 'Lmnn', None],
            default = None,
            help = soft_constraints_help)
    
    args = parser.parse_args()
    db, cursor = mysql_tools.getDbConnection()
    ## Check whether the dataset has been loaded before
    if not mysql_tools.databaseExists(cursor, args.project, args.dataset):
        load_dataset = Dataset(args.project, args.dataset,
                db, cursor)
        load_dataset.load()
    
    # Alerts configuration
    projection_conf = None
    if args.soft_constraints is not None:
        projection_conf = ProjectionConfFactory.getFactory().fromParam(
                args.soft_constraints)
    clustering_conf = ClusteringConfFactory.getFactory().fromParam(
            args.clustering_algo,
            args.num_clusters, 
            projection_conf = projection_conf)
    alerts_conf = AlertsConfiguration(args.top_n_alerts, args.detection_threshold,
            clustering_conf)
    
    # Supervised learning configuration
    conf = SupervisedLearningConfFactory.getFactory().fromParam(
            args.model_class,
            args.num_folds, args.sample_weight,
            alerts_conf = alerts_conf)
    conf.setUnlabeled(labels_annotations = 'annotations')
    
    experiment = SupervisedLearningExperiment(
            args.project, args.dataset, db, cursor)
    experiment.setFeaturesFilenames(args.features_files)
    
    if args.validation_dataset is not None:
        conf.setTestDataset(args.validation_dataset, experiment)
    else:
        conf.setRandomSplit(args.test_size)
    
    experiment.setSupervisedLearningConf(conf)
    experiment.initLabels('true_labels.csv')
    experiment.export()
    
    datasets = SupervisedLearningDatasets(experiment)
    datasets.generateDatasets()
    
    learning = experiment.supervised_learning_conf.model_class(experiment, datasets)
    learning.run()
    
    mysql_tools.closeDb(db, cursor)
    if args.validation_dataset is not None:
        mysql_tools.closeDb(
                experiment.supervised_learning_conf.test_conf.test_exp.db,
                experiment.supervised_learning_conf.test_conf.test_exp.cursor)
