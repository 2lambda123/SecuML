#!/usr/bin/python2

## SecuML
## Copyright (C) 2016  ANSSI
## 
## SecuML is free software; you can redistribute it and/or modify
## it under the terms of the GNU General Public License as published by
## the Free Software Foundation; either version 2 of the License, or
## (at your option) any later version.
## 
## SecuML is distributed in the hope that it will be useful,
## but WITHOUT ANY WARRANTY; without even the implied warranty of
## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
## GNU General Public License for more details.
## 
## You should have received a copy of the GNU General Public License along
## with SecuML. If not, see <http://www.gnu.org/licenses/>.

import argparse
import matplotlib
matplotlib.use('Agg')

from SecuML.ActiveLearning.Configuration.IlabConfiguration import IlabConfiguration
from SecuML.ActiveLearning.Datasets import Datasets
from SecuML.ActiveLearning.Iterations import Iterations

from SecuML.Data.Dataset import Dataset

from SecuML.Experiment.ActiveLearningExperiment import ActiveLearningExperiment

from SecuML.SupervisedLearning.Configuration import SupervisedLearningConfFactory
from SecuML.UnsupervisedLearning.Configuration import ProjectionConfFactory
from SecuML.UnsupervisedLearning.Configuration import ClusteringConfFactory

from SecuML.Tools import mysql_tools

if __name__ == '__main__':
    description  = 'Interactive Labeling Procedure'
    parser = argparse.ArgumentParser(description = description, 
            formatter_class = argparse.RawTextHelpFormatter)
    
    parser.add_argument('project') 
    parser.add_argument('dataset')
    parser.add_argument('--features', '-f', 
            dest = 'features_files', 
            nargs = '+',
            required = False, 
            default = ['features.csv'],
            help = 'CSV files containing the features.')


    ## Active learning parameters
    al_group = parser.add_argument_group(
            'Active learning parameters')
    al_group.add_argument('--init-labels-file', 
            default = 'init_labels',
            help = 'CSV file containing the initial labels used to learn the first ' + 
            'supervised detection model.')
    labeling_strategy_help  = '* random_sampling: \n\t At each iteration, random unlabeled instances are queried for annotation.\n'
    labeling_strategy_help += '* closest_to_boundary: \n\t At each iteration, the closest instances to the decision boundary are queried for annotation.\n'
    labeling_strategy_help += '* Cesa_Bianchi: \n\t Adapdation for batch active learning of the online labeling strategy '
    labeling_strategy_help += 'described in "Worst-case analysis of selective sampling for linear classification" (Cesa-Bianchi et al.).\n'
    labeling_strategy_help += '* ILAB: \n\t Novel labeling strategy. Instances close to the decision boundary are queried for annotation. '
    labeling_strategy_help += 'Clusters are built from the confident predictions and some instances are queried for annotation in each cluster.'
    al_group.add_argument('--labeling-strategy',
            choices = ['random_sampling', 'closest_to_boundary', 'Cesa_Bianchi', 'ILAB'],
            default = 'ILAB',
            help = labeling_strategy_help)
    al_group.add_argument('--budget',
            type = int,
            default = 2000,
            help = 'Total number of annotations asked from the user during the labeling procedure.')
    al_group.add_argument('--num-annotations',
            type = int,
            default = 100,
            help = 'Number of annotations asked from the user at each iteration.')
    auto_help  = 'When set to True, the annotation queries are answered automatically by an oracle '
    auto_help += 'with the ground truth labels stored in true_labels.csv. '
    auto_help += '\nOtherwise, the user must answer some annotation queries in the web interface '
    auto_help += 'at each iteration.'
    al_group.add_argument('--auto',
            dest = 'auto',
            action = 'store_true',
            default = False,
            help = auto_help)
    
    ## Supervised learning parameters
    supervised_group = parser.add_argument_group(
            'Supervised learning parameters')
    supervised_group.add_argument('--model-class',
            choices = ['LogisticRegression', 'Svc'],
            default = 'LogisticRegression')
    supervised_group.add_argument('--num-folds',
            type = int,
            default = 4)
    sample_weight_help  = 'When set to True, the detection model is learned with '
    sample_weight_help += 'sample weights inverse to the proportion of the family '
    sample_weight_help += 'in the dataset. Useless if the sublabels are not specified.'
    supervised_group.add_argument('--sample-weight',
            action = 'store_true',
            default = False,
            help = sample_weight_help)
    supervised_group.add_argument('--validation-dataset',
            default = None,
            help = 'The validation dataset must contain true labels.')
    
    
    # ILAB parameters
    ilab_group = parser.add_argument_group(
            'ILAB parameters')
    ilab_group.add_argument('--clustering-algo',
            default = 'Kmeans',
            choices = ['Kmeans', 'GaussianMixture'])
    ilab_group.add_argument('--soft-constraints',
            choices = ['Lda', 'Lmnn', 'Nca', 'Rca', None], 
            default = None,
            help = 'Projection performed before building the clustering. ' + 
            'By default the instances are not projected.')
    ilab_group.add_argument('--num-unsure',
            type = int,
            default = 10,
            help = 'Number of instances queried close to the decision boundary.')
    ilab_group.add_argument('--r',
            type = int,
            default = 10,
            help = 'Number of annotations asked from the user for each cluster built from the confident predictions.')
    
    # Cesa-Bianchi parameters
    cesa_group = parser.add_argument_group(
            'Cesa-Bianchi parameters')
    cesa_group.add_argument('--b',
            type = float,
            default = 0.1)
    
    args = parser.parse_args()
    
    db, cursor = mysql_tools.getDbConnection()
    ## Check whether the dataset has been loaded before
    if not mysql_tools.databaseExists(cursor, args.project, args.dataset):
        load_dataset = Dataset(args.project, args.dataset,
                db, cursor)
        load_dataset.load()
    
    conf = SupervisedLearningConfFactory.getFactory().fromParam(
            args.model_class,
            args.num_folds, args.sample_weight)
    conf.setUnlabeled(labels_annotations = 'annotations')
    
    experiment = ActiveLearningExperiment(args.project, args.dataset, db, cursor)
    
    if args.labeling_strategy == 'ILAB':
        projection_conf = None
        if args.soft_constraints is not None:
            projection_conf = ProjectionConfFactory.getFactory().fromParam(
                    args.soft_constraints, sublabels_supervision = True)
        clustering_conf = ClusteringConfFactory.getFactory().fromParam(
                args.clustering_algo,
                2, 
                num_results = args.r,
                projection_conf = projection_conf)
        ilab_conf = IlabConfiguration(0.33,
                False, 
                False,
                True,
                args.num_unsure,
                clustering_conf)
        ilab_conf.setNumberAnnotations(args.r)
        experiment.setILAB(ilab_conf)
    
    elif args.labeling_strategy == 'closest_to_boundary':
        experiment.setClosestToBoundary(args.num_annotations)
    
    elif args.labeling_strategy == 'random_sampling':
        experiment.setRandomSamplingLabelChecking(args.num_annotations)
    
    elif args.labeling_strategy == 'Cesa_Bianchi':
        experiment.setCesaBianchi(args.b, args.num_annotations)
    
    experiment.setFeaturesFilenames(args.features_files)
    experiment.setValidation(args.validation_dataset)
    experiment.setSupervisedLearningConf(conf)
    experiment.initLabels(args.init_labels_file)
    experiment.export()
    
    datasets = Datasets(experiment)
    iterations = Iterations(experiment, datasets, args.budget, args.auto)
    iterations.runIterations()
    
    mysql_tools.closeDb(db, cursor)
