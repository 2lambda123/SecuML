#!/usr/bin/python2

## SecuML
## Copyright (C) 2016  ANSSI
##
## SecuML is free software; you can redistribute it and/or modify
## it under the terms of the GNU General Public License as published by
## the Free Software Foundation; either version 2 of the License, or
## (at your option) any later version.
##
## SecuML is distributed in the hope that it will be useful,
## but WITHOUT ANY WARRANTY; without even the implied warranty of
## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
## GNU General Public License for more details.
##
## You should have received a copy of the GNU General Public License along
## with SecuML. If not, see <http://www.gnu.org/licenses/>.

import argparse
import matplotlib
matplotlib.use('Agg')

from SecuML.Classification.Configuration.AlertsConfiguration import AlertsConfiguration
from SecuML.Classification.Configuration import ClassifierConfFactory
from SecuML.Classification.ClassifierDatasets import ClassifierDatasets
from SecuML.Clustering.Configuration import ClusteringConfFactory
from SecuML.Data.Dataset import Dataset
from SecuML.Experiment.ClassificationExperiment import ClassificationExperiment
from SecuML.Tools import mysql_tools


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
            description = 'Learn a detection model. ' +
            'The labels must be stored in labels/true_labels.csv.')
    parser.add_argument('project')
    parser.add_argument('dataset')
    parser.add_argument('--features', '-f',
            dest = 'features_files',
            nargs = '+',
            required = False,
            default = ['features.csv'],
            help = 'CSV files containing the features.')

    ## Cross validation parameters
    cv_group = parser.add_argument_group(
            'Cross validation parameters')
    cv_group.add_argument('--num-folds',
            type = int,
            default = 4)
    cv_group.add_argument('--model-class',
            choices = ['LogisticRegression', 'Svc', 'GaussianNaiveBayes'],
            default = 'LogisticRegression')
    sample_weight_help  = 'When set to True, the detection model is learned with '
    sample_weight_help += 'sample weights inverse to the proportion of the family '
    sample_weight_help += 'in the dataset. Useless if the families are not specified.'
    cv_group.add_argument('--sample-weight',
            action = 'store_true',
            default = False,
            help = sample_weight_help)

    ## Validation parameters
    validation_help  = 'Validation parameters: \n '
    validation_help += 'The detection model is validated with a proportion of '
    validation_help += 'the instances in the input dataset, or with a separate validation'
    validation_help += ' dataset. By default 10% of the instances are used for validation'
    validation_group = parser.add_argument_group(validation_help)
    validation_group.add_argument('--test-size',
            type = float,
            default = 0.1)
    validation_group.add_argument('--validation-dataset',
            default = None)

    ## Alerts
    alerts_group = parser.add_argument_group(
            'Alerts parameters')
    alerts_group.add_argument('--top-n-alerts',
            default = 100,
            help = 'Number of most confident alerts displayed.')
    alerts_group.add_argument('--detection-threshold',
            type = float,
            default = 0.8,
            help = 'An alert is raised if the predicted probability of maliciousness ' +
            'is above this threshold.')
    alerts_group.add_argument('--clustering-algo',
            default = 'Kmeans',
            choices = ['Kmeans', 'GaussianMixture'],
            help = 'Clustering algorithm to analyse the alerts.')
    alerts_group.add_argument('--num-clusters',
            type = int,
            default = 4,
            help = 'Number of clusters built from the alerts.')

    args = parser.parse_args()
    db, cursor = mysql_tools.getDbConnection()
    ## Check whether the dataset has been loaded before
    if not mysql_tools.databaseExists(cursor, args.project, args.dataset):
        load_dataset = Dataset(args.project, args.dataset,
                db, cursor)
        load_dataset.load()

    # Alerts configuration
    clustering_conf = ClusteringConfFactory.getFactory().fromParam(
            args.clustering_algo,
            args.num_clusters)
    alerts_conf = AlertsConfiguration(args.top_n_alerts, args.detection_threshold,
            clustering_conf)

    # Supervised learning configuration
    classification_args = {}
    classification_args['num_folds']            = args.num_folds
    classification_args['sample_weight']        = args.sample_weight
    classification_args['families_supervision'] = False
    classification_args['alerts_conf']          = alerts_conf
    conf = ClassifierConfFactory.getFactory().fromParam(
            args.model_class, classification_args)
    conf.setUnlabeled(labels_annotations = 'annotations')

    experiment = ClassificationExperiment(
            args.project, args.dataset, db, cursor)
    experiment.setFeaturesFilenames(args.features_files)

    if args.validation_dataset is not None:
        conf.setTestDataset(args.validation_dataset, experiment)
    else:
        conf.setRandomSplit(args.test_size)

    experiment.setClassifierConf(conf)
    experiment.initLabels('true_labels.csv')
    experiment.export()

    datasets = ClassifierDatasets(experiment)
    datasets.generateDatasets()
    learning = experiment.classification_conf.model_class(experiment, datasets)
    learning.run()

    mysql_tools.closeDb(db, cursor)
    if args.validation_dataset is not None:
        mysql_tools.closeDb(
                experiment.classification_conf.test_conf.test_exp.db,
                experiment.classification_conf.test_conf.test_exp.cursor)
